{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "improving-prize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_164:0\", shape=(1, 512, 512, 3), dtype=float32)\n",
      "Tensor(\"Placeholder_8:0\", shape=(1, 512, 512, 3), dtype=float32)\n",
      "Tensor(\"concat_22:0\", shape=(2, 512, 512, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "tf.compat.v1.disable_eager_execution() #must put at the TOP\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# This is the path to the image you want to extract texture from\n",
    "target_image_path = 'C:/Users/MrLin/Documents/Experiments/Fine_Scale_Autoencoder_Lichen/Results/test_images/input/New folder/05.png'\n",
    "\n",
    "# Dimensions of the generated picture.\n",
    "img_height = 512 #set intended image size to be given to load_img below\n",
    "img_width = 512\n",
    "\n",
    "def process_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_height, img_width))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array *= (1/255)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "def deprocess_image(img_tensor):\n",
    "    img_tensor *= 255\n",
    "    img_tensor = np.clip(img_tensor, 0, 255)\n",
    "    img_tensor = np.uint8(img_tensor)\n",
    "    return img_tensor\n",
    "\n",
    "target_image = K.constant(process_image(target_image_path))\n",
    "learned_image = K.placeholder((1, img_height, img_width, 3))\n",
    "\n",
    "#new input that we will attach to the model that will be involved in the image learning algorithm\n",
    "input_tensor = K.concatenate([target_image,\n",
    "                              learned_image], axis=0)\n",
    "print(target_image)\n",
    "print(learned_image)\n",
    "print(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "enabling-bride",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FCN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(2, 512, 512, 3)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (2, 512, 512, 32)         4736      \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (2, 512, 512, 32)         50208     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (2, 512, 512, 32)         128       \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (2, 512, 512, 64)         51264     \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (2, 512, 512, 64)         102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (2, 512, 512, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (2, 512, 512, 64)         36928     \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (2, 512, 512, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (2, 512, 512, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (2, 512, 512, 64)         4160      \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (2, 512, 512, 64)         4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (2, 512, 512, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (2, 512, 512, 3)          195       \n",
      "=================================================================\n",
      "Total params: 291,939\n",
      "Trainable params: 291,491\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Rebuild model with a the new input tensor\n",
    "new_input = Input(tensor=input_tensor)\n",
    "x = layers.Conv2D(32, 7, strides=(1, 1), activation='relu', padding='same')(new_input)\n",
    "x = layers.Conv2D(32, 7, strides=(1, 1), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Conv2D(64, 5, strides=(1, 1), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(64, 5, strides=(1, 1), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Conv2D(64, 3, strides=(1, 1), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(64, 3, strides=(1, 1), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Conv2D(64, 1, strides=(1, 1), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(64, 1, strides=(1, 1), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "FCN_output = layers.Conv2D(3, 1, strides=(1, 1), activation='relu', padding='same')(x)\n",
    "FCN = keras.Model(new_input, FCN_output, name='FCN')\n",
    "FCN.load_weights(\"FCN512_2_weights\")\n",
    "FCN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "coordinated-cabin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv2d_81': <tf.Tensor 'conv2d_81/Relu:0' shape=(2, 512, 512, 32) dtype=float32>,\n",
       " 'conv2d_82': <tf.Tensor 'conv2d_82/Relu:0' shape=(2, 512, 512, 32) dtype=float32>,\n",
       " 'batch_normalization_36': <tf.Tensor 'batch_normalization_36/cond/Identity:0' shape=(2, 512, 512, 32) dtype=float32>,\n",
       " 'conv2d_83': <tf.Tensor 'conv2d_83/Relu:0' shape=(2, 512, 512, 64) dtype=float32>,\n",
       " 'conv2d_84': <tf.Tensor 'conv2d_84/Relu:0' shape=(2, 512, 512, 64) dtype=float32>,\n",
       " 'batch_normalization_37': <tf.Tensor 'batch_normalization_37/cond/Identity:0' shape=(2, 512, 512, 64) dtype=float32>,\n",
       " 'conv2d_85': <tf.Tensor 'conv2d_85/Relu:0' shape=(2, 512, 512, 64) dtype=float32>,\n",
       " 'conv2d_86': <tf.Tensor 'conv2d_86/Relu:0' shape=(2, 512, 512, 64) dtype=float32>,\n",
       " 'batch_normalization_38': <tf.Tensor 'batch_normalization_38/cond/Identity:0' shape=(2, 512, 512, 64) dtype=float32>,\n",
       " 'conv2d_87': <tf.Tensor 'conv2d_87/Relu:0' shape=(2, 512, 512, 64) dtype=float32>,\n",
       " 'conv2d_88': <tf.Tensor 'conv2d_88/Relu:0' shape=(2, 512, 512, 64) dtype=float32>,\n",
       " 'batch_normalization_39': <tf.Tensor 'batch_normalization_39/cond/Identity:0' shape=(2, 512, 512, 64) dtype=float32>,\n",
       " 'conv2d_89': <tf.Tensor 'conv2d_89/Relu:0' shape=(2, 512, 512, 3) dtype=float32>}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a dict of models/layers that can be easily accessed to get intermediate outputs\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in FCN.layers[1:]]) #we wont need the output of input layer\n",
    "outputs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "studied-carter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat_23:0\", shape=(451,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def get_GAP(layer_output):\n",
    "    #input is a (height, width, channels) tensor. We first permute_dimensions to (channels, height, width). Then take the sum over all pixels in each channel.\n",
    "    #each element j of the output is the mean across all pixels in the channel j\n",
    "    return K.mean(K.batch_flatten(K.permute_dimensions(layer_output,(2,0,1))), axis=1)\n",
    "    \n",
    "GAP_target_img = []\n",
    "GAP_learned_img = []\n",
    "\n",
    "# cycle through all non-batch norm layers and concat the GAP into one long vector with length equal to the number of channels in the entire network\n",
    "for name in outputs_dict:\n",
    "    if name.find('batch_normalization') == -1: # skip batch norm layers\n",
    "        layer_features = outputs_dict[name]\n",
    "        GAP_target_img.append(get_GAP(layer_features[0]))\n",
    "        GAP_learned_img.append(get_GAP(layer_features[1]))\n",
    "    \n",
    "GAP_target_img = K.concatenate(GAP_target_img, axis=0)\n",
    "GAP_learned_img = K.concatenate(GAP_learned_img, axis=0)\n",
    "GAP_learned_img\n",
    "\n",
    "Loss = K.sqrt(K.sum(K.square(GAP_target_img-GAP_learned_img)))\n",
    "grads = K.gradients(Loss, learned_image)[0]\n",
    "\n",
    "print(GAP_target_img)\n",
    "fetch_loss_and_grads = K.function([learned_image], [Loss, grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dimensional-occasions",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        #reshape optimizers vector into shape of input image\n",
    "        x = x.reshape((1, img_height, img_width, 3)) #super long vector from optimizer being reshaped into a tensor. This is the learned image\n",
    "        outs = fetch_loss_and_grads([x])#get loss and grads using this (current) img as input\n",
    "        loss_value = outs[0]\n",
    "        grad_values = outs[1].flatten().astype('float64') #reshape gradient tensor back into a vector for the optimizer\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values) #copy creates a new copy instead of a new reference name to the same object\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "completed-entrance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 3)\n",
      "Start of iteration 0\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-7.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-7.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-8.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-8.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-9.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-9.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-11.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-11.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-12.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-12.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-7.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-7.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-8.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-8.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-9.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-9.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-10.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-10.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-11.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-11.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-12.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-12.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Current loss value: 6.424539\n",
      "(512, 512, 3)\n",
      "Image saved as learned_image_05_at_iteration_0.png\n",
      "Iteration 0 completed in 5s\n",
      "Start of iteration 1\n",
      "Current loss value: 2.1694627\n",
      "Start of iteration 2\n",
      "Current loss value: 0.3884461\n",
      "Start of iteration 3\n",
      "Current loss value: 0.14136195\n",
      "Start of iteration 4\n",
      "Current loss value: 0.10618133\n",
      "Start of iteration 5\n",
      "Current loss value: 0.091603875\n",
      "(512, 512, 3)\n",
      "Image saved as learned_image_05_at_iteration_5.png\n",
      "Iteration 5 completed in 4s\n",
      "Start of iteration 6\n",
      "Current loss value: 0.0856784\n",
      "Start of iteration 7\n",
      "Current loss value: 0.08242793\n",
      "Start of iteration 8\n",
      "Current loss value: 0.07973346\n",
      "Start of iteration 9\n",
      "Current loss value: 0.077586696\n",
      "Start of iteration 10\n",
      "Current loss value: 0.07404898\n",
      "(512, 512, 3)\n",
      "Image saved as learned_image_05_at_iteration_10.png\n",
      "Iteration 10 completed in 4s\n",
      "Start of iteration 11\n",
      "Current loss value: 0.07141453\n",
      "Start of iteration 12\n",
      "Current loss value: 0.06758281\n",
      "Start of iteration 13\n",
      "Current loss value: 0.06534316\n",
      "Start of iteration 14\n",
      "Current loss value: 0.06405276\n",
      "Start of iteration 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 0.062284857\n",
      "(512, 512, 3)\n",
      "Image saved as learned_image_05_at_iteration_15.png\n",
      "Iteration 15 completed in 4s\n"
     ]
    }
   ],
   "source": [
    "# Run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the loss.\n",
    "# Note that `scipy.optimize.fmin_l_bfgs_b` can only process flat vectors.\n",
    "result_prefix = 'learned_image_05'\n",
    "iterations = 1+15\n",
    "\n",
    "initialcond_image_path = 'C:/Users/MrLin/Documents/Experiments/Fine_Scale_Autoencoder_Lichen/noiz.png'\n",
    "x_vect = process_image(initialcond_image_path)\n",
    "print(x_vect.shape)\n",
    "\n",
    "x_vect = x_vect.flatten()\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x_vect, min_val, info = fmin_l_bfgs_b(evaluator.loss, x_vect,\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    \n",
    "    print('Current loss value:', min_val)\n",
    "    if i%5==0:\n",
    "        # Save current generated image\n",
    "        img = x_vect.copy().reshape((img_height, img_width, 3)) #copy needed since we deprocess and we dont want to change the original x. since x will be used in next iteration\n",
    "        img = deprocess_image(img)\n",
    "        fname = result_prefix + '_at_iteration_%d.png' % i\n",
    "        print(img.shape)\n",
    "        pil_img = Image.fromarray(img)\n",
    "        pil_img.save('C:/Users/MrLin/Documents/Experiments/Fine_Scale_Autoencoder_Lichen/Results/' + fname)\n",
    "\n",
    "#         imsave(fname, img)\n",
    "        end_time = time.time()\n",
    "        print('Image saved as', fname)\n",
    "        print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
